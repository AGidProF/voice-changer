{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9DR6u58NJCl"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deiteris/voice-changer/blob/master-custom/Colab_RealtimeVoiceChanger.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lbbmx_Vjl0zo"
      },
      "source": [
        "### [w-okada's Voice Changer](https://github.com/deiteris/voice-changer) | **Google Colab**\n",
        "\n",
        "---\n",
        "\n",
        "## **READ ME - VERY IMPORTANT**\n",
        "\n",
        "You can use the following settings for optimal results:\n",
        "\n",
        "Best performance (with good quality): `f0: fcpe | Chunk: 80.0ms or higher | Extra: 5s`<br>\n",
        "Best quality: `f0: rmvpe | Chunk: 112.0ms or higher | Extra: 5s`<br>\n",
        "**Don't forget to select your Colab GPU in the GPU field (<b>Tesla T4</b>, for free users)*\n",
        "\n",
        "You can tune `Chunk` for lower/higher delay and `Extra` for better quality.\n",
        "\n",
        "<br><br>\n",
        "\n",
        "---\n",
        "\n",
        "### Always use Colab GPU (**VERY VERY VERY IMPORTANT!**)\n",
        "You need to use a Colab GPU so the Voice Changer can work faster and better\\\n",
        "Use the menu above and click on **Runtime** » **Change runtime** » **Hardware acceleration** to select a GPU (**T4 is the free one**)\n",
        "\n",
        "---\n",
        "\n",
        "# **Credits and Support**\n",
        "Realtime Voice Changer by [w-okada](https://github.com/w-okada)<br>\n",
        "Original instructions by [Hina](https://github.com/HinaBl)<br>\n",
        "\n",
        "Need help? [AI Hub Discord](https://discord.gg/aihub) » ***#help-realtime-vc***\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86wTFmqsNMnD"
      },
      "outputs": [],
      "source": [
        "#=================Updated=================\n",
        "# @title **[1]** Clone repository and install dependencies\n",
        "# @markdown This first step will download the latest version of Voice Changer and install the dependencies. **It can take some time to complete.**\n",
        "import os\n",
        "import time\n",
        "from google.colab import drive\n",
        "\n",
        "#@markdown ---\n",
        "# @title **[Optional]** Connect to Google Drive\n",
        "# @markdown Using Google Drive will automatically save your uploaded models for later use. Make sure you have sufficient amount of space on your Google Drive.\n",
        "\n",
        "%cd /content\n",
        "\n",
        "Use_Drive=True #@param {type:\"boolean\"}\n",
        "\n",
        "!pip install colorama python-dotenv pyngrok --quiet\n",
        "\n",
        "from colorama import Fore, Style\n",
        "import requests\n",
        "\n",
        "print(f\"{Fore.CYAN}> Downloading prebuilt executable...{Style.RESET_ALL}\")\n",
        "\n",
        "res = requests.get('https://api.github.com/repos/deiteris/voice-changer/releases/latest')\n",
        "release_info = res.json()\n",
        "\n",
        "for asset in release_info['assets']:\n",
        "   if not asset['name'].startswith('voice-changer-linux-amd64-cuda.tar.gz'):\n",
        "      continue\n",
        "   download_url = asset['browser_download_url']\n",
        "   !wget -q --show-progress {download_url}\n",
        "\n",
        "print(f\"{Fore.GREEN}> Unpacking...{Style.RESET_ALL}\")\n",
        "!cat voice-changer-linux-amd64-cuda.tar.gz.* | tar xzf -\n",
        "print(f\"{Fore.GREEN}> Finished unpacking!{Style.RESET_ALL}\")\n",
        "!rm -rf voice-changer-linux-amd64-cuda.tar.gz.*\n",
        "\n",
        "%cd MMVCServerSIO\n",
        "\n",
        "if Use_Drive and not os.path.exists('/content/drive'):\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  !mkdir -p /content/drive/MyDrive/voice-changer/server/model_dir\n",
        "  !mkdir -p /content/drive/MyDrive/voice-changer/server/pretrain\n",
        "  !rm -rf /content/MMVCServerSIO/server/model_dir\n",
        "  !rm -rf /content/MMVCServerSIO/server/pretrain\n",
        "\n",
        "  time.sleep(5)\n",
        "\n",
        "  os.symlink(\"/content/drive/MyDrive/voice-changer/server/model_dir\", \"/content/MMVCServerSIO/model_dir\", True)\n",
        "  os.symlink(\"/content/drive/MyDrive/voice-changer/server/pretrain\", \"/content/MMVCServerSIO/pretrain\", True)\n",
        "\n",
        "print(f\"{Fore.GREEN}> Successfully downloaded and unpacked the binary!{Style.RESET_ALL}\")\n",
        "\n",
        "print(f\"{Fore.CYAN}> Installing libportaudio2...{Style.RESET_ALL}\")\n",
        "!apt-get -y install libportaudio2 -qq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6U7K5ZW3NJCx"
      },
      "outputs": [],
      "source": [
        "#=================Updated=================\n",
        "# @title **[2]** Set server configuration\n",
        "# @markdown This cell will set the server configuration.\n",
        "\n",
        "%cd /content/MMVCServerSIO\n",
        "\n",
        "from dotenv import set_key\n",
        "\n",
        "set_key('.env', \"SAMPLE_MODE\", \"\")\n",
        "\n",
        "Ready = True"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    #@title **[Optional Cell For V1 Old Okada Voice Changer]** Upload a voice model (Run this before running the Voice Changer)\n",
        "    #@markdown Find your model here [voice-models](https://voice-models.com/)\n",
        "    # @markdown ---\n",
        "    model_slot = \"0\" #@param ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199']\n",
        "\n",
        "    !rm -rf model_dir/$model_slot\n",
        "    #@markdown **[Optional]** Add an icon to the model (Kosongin aja gapapa / It's okay to leave it blank)\n",
        "    icon_link = \"\"  #@param {type:\"string\"}\n",
        "    icon_link = '\"'+icon_link+'\"'\n",
        "    !mkdir model_dir\n",
        "    !mkdir model_dir/$model_slot\n",
        "    #@markdown Put your model's download link here `(must be a zip file and don't use GPT-SoVITS Model)` only supports **huggingface.co** & **google drive**<br>\n",
        "    model_link = \"https://huggingface.co/makiligon/RVC-Models/resolve/main/Furina.zip\"  #@param {type:\"string\"}\n",
        "\n",
        "    if model_link.startswith(\"https://www.weights.gg\") or model_link.startswith(\"https://weights.gg\"):\n",
        "        print(\"Links from weights.gg is no longer supported.\")\n",
        "        sys.exit()\n",
        "    elif model_link.startswith(\"https://drive.google.com\"):\n",
        "        model_link = '\"'+model_link+'\"'\n",
        "        !gdown $model_link --fuzzy -O model.zip\n",
        "        print(\"Model from Drive\")\n",
        "    elif model_link.startswith(\"https://huggingface.co\"):\n",
        "        model_link = model_link\n",
        "        model_link = '\"'+model_link+'\"'\n",
        "        !curl -L $model_link > model.zip\n",
        "        print(\"Model from huggingface Link\")\n",
        "    else:\n",
        "        model_link = model_link\n",
        "        model_link = '\"'+model_link+'\"'\n",
        "        !curl -L -O $model_link\n",
        "        !mv ./*.pth model_dir/$model_slot/\n",
        "        print('Model(.pth) or a direct model link.')\n",
        "\n",
        "    # Conditionally set the iconFile based on whether icon_link is empty\n",
        "    if icon_link == '\"\"':\n",
        "        iconFile = \"\"\n",
        "        print(\"icon_link is empty, so no icon file will be downloaded.\")\n",
        "    else:\n",
        "        iconFile = \"icon.png\"\n",
        "        !curl -L $icon_link > model_dir/$model_slot/icon.png\n",
        "\n",
        "    !unzip model.zip -d model_dir/$model_slot\n",
        "\n",
        "    !mv model_dir/$model_slot/*/* model_dir/$model_slot/\n",
        "    !rm -rf model_dir/$model_slot/*/\n",
        "    !rm -rf model.zip\n",
        "    #@markdown **Model Voice Conversion Setting**\n",
        "    Tune = 12  #@param {type:\"slider\",min:-24,max:24,step:1}\n",
        "    Index = 0  #@param {type:\"slider\",min:0,max:1,step:0.1}\n",
        "\n",
        "    param_link = \"\"\n",
        "    if param_link == \"\":\n",
        "        paramset = requests.get(\"https://pastebin.com/raw/P6ar4baa\").text\n",
        "        exec(paramset)\n",
        "\n",
        "    clear_output()\n",
        "    print(\"\\033[93mModel with the name of \"+model_name+\" has been Imported to slot \"+model_slot)\n"
      ],
      "metadata": {
        "id": "FCbv7OaHPYYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lLWQuUd7WW9U"
      },
      "outputs": [],
      "source": [
        "#=======================Updated=========================\n",
        "\n",
        "# @title Start Server **using ngrok**\n",
        "# @markdown This cell will start the server, the first time that you run it will download the models, so it can take a few minutes (usually ~1-2 minutes)\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown You'll need a ngrok account, but <font color=green>**it's free**</font> and easy to create!\n",
        "# @markdown ---\n",
        "# @markdown **1** - Create a <font color=green>**free**</font> account at [ngrok](https://dashboard.ngrok.com/signup) or **login with Google/Github account**\\\n",
        "# @markdown **2** - If you didn't logged in with Google/Github, you will need to **verify your e-mail**!\\\n",
        "# @markdown **3** - Click [this link](https://dashboard.ngrok.com/get-started/your-authtoken) to get your auth token, and place it here:\n",
        "Token = 'TOKEN_HERE' # @param {type:\"string\"}\n",
        "# @markdown **4** - *(optional)* Change to a region near to you\\\n",
        "# @markdown `Default Region: ap - Asia/Pacific (Singapore)`\n",
        "Region = \"ap - Asia/Pacific (Singapore)\" # @param [\"ap - Asia/Pacific (Singapore)\", \"au - Australia (Sydney)\",\"eu - Europe (Frankfurt)\", \"in - India (Mumbai)\",\"jp - Japan (Tokyo)\",\"sa - South America (Sao Paulo)\", \"us - United States (Ohio)\"]\n",
        "\n",
        "#@markdown **5** - *(optional)* Other options:\n",
        "ClearConsole = True  # @param {type:\"boolean\"}\n",
        "\n",
        "# ---------------------------------\n",
        "# DO NOT TOUCH ANYTHING DOWN BELOW!\n",
        "# ---------------------------------\n",
        "\n",
        "if not globals().get('Ready', False):\n",
        "    print(\"Go back and run first and second cells.\")\n",
        "else:\n",
        "    from pyngrok import conf, ngrok\n",
        "    MyConfig = conf.PyngrokConfig()\n",
        "    MyConfig.auth_token = Token\n",
        "    MyConfig.region = Region[0:2]\n",
        "    conf.get_default().authtoken = Token\n",
        "    conf.get_default().region = Region\n",
        "    conf.set_default(MyConfig);\n",
        "\n",
        "    import threading, time, socket\n",
        "    PORT = 18888\n",
        "\n",
        "    import json\n",
        "    from pyngrok import ngrok\n",
        "    from IPython.display import clear_output\n",
        "\n",
        "    ngrokConnection = ngrok.connect(PORT)\n",
        "    public_url = ngrokConnection.public_url\n",
        "    set_key('.env', \"ALLOWED_ORIGINS\", json.dumps([public_url]))\n",
        "\n",
        "    def wait_for_server():\n",
        "        while True:\n",
        "            time.sleep(0.5)\n",
        "            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "            result = sock.connect_ex(('127.0.0.1', PORT))\n",
        "            if result == 0:\n",
        "                break\n",
        "            sock.close()\n",
        "        if ClearConsole:\n",
        "            clear_output()\n",
        "        print(\"--------- SERVER READY! ---------\")\n",
        "        print(\"Your server is available at:\")\n",
        "        print(public_url)\n",
        "        print(\"---------------------------------\")\n",
        "\n",
        "    threading.Thread(target=wait_for_server, daemon=True).start()\n",
        "\n",
        "    !./MMVCServerSIO\n",
        "\n",
        "    ngrok.disconnect(ngrokConnection.public_url)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}